---
title: Elasticsearch笔记（三）
date: 2020/02/04
updated: 2020/02/04
comments: true
categories: 
- [笔记, database, elasticsearch]
tags: 
- elasticsearch
- 非关系型数据库
---
## Elasticsearch笔记（三）

### 十、分片内部原理

#### 1. 使文本可被搜索
+ 传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多个值的能力(单词)
+ 最好的支持一个字段多个值需求的数据结构是倒排索引(inverted-index)。倒排索引包含一个有序列表，列表包含所有文档出现过的不重复词项，对于每一个词项，包含了它所有曾出现过文档的列表
+ 早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到

#### 2. 不变性
+ 倒排索引被写入磁盘后是不可改变的，它永远不会修改，不变性有重要的价值
    1. 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题
    2. 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升
    3. 其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化
    4. 写入单个大的倒排索引允许数据被压缩，减少磁盘I/O和需要被缓存到内存的索引的使用量
+ 一个不变的索引也有不好的地方。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制

#### 3. 动态更新索引
+ 通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到，从最早的开始，​查询完后再对结果进行合并
+ Elasticsearch基于Lucene，一个Lucene索引我们在Elasticsearch称作分片，一个Elasticsearch索引是分片的集合。一个Lucene索引包含一个提交点和三个段，Lucene这个java库引入了按段搜索的概念，每一段本身都是一个倒排索引，但索引在Lucene中除表示所有段的集合外，还增加了一个列出了所有已知段的文件(提交点)
+ 当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引
+ 段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个`.del`文件，文件中会列出这些被删除文档的段信息
+ 当一个文档被删除或被更新时(相当于旧版本文档被删除)实际上只是在`.del`文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除(在后续操作中被标记删除的文档最终会被系统移除)

#### 4. 近实时搜索
+ 新文档在几分钟之内即可被检索，但这样还是不够快，磁盘在这里成为了瓶颈，我们需要的是一个更轻量的方式来使一个文档可被搜索
+ 在Elasticsearch和磁盘之间是文件系统缓存。在内存索引缓冲区(在内存缓冲区中包含了新文档的Lucene索引)中的文档会被写入到一个新的段中(缓冲区的内容已经被写入一个可被搜索的段中，但还没有进行提交)
+ 新段会被先写入到文件系统缓存(这一步代价会比较低)，稍后再被刷新到磁盘(​这一步代价比较高)。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了
+ 在Elasticsearch中，写入和打开一个新段的轻量的过程叫做`refresh`。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说Elasticsearch是近实时搜索(文档的变化并不是立即对搜索可见，但会在一秒之内变为可见)
+ 尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。相反，你的应用需要意识到Elasticsearch的近实时的性质，并接受它的不足
1. 手动刷新所有的索引 `POST /_refresh`
2. 手动刷新`blogs`索引 `POST /blogs/_refresh`
3. 设置自动刷新的时间间隔(`refresh_interval`需要一个持续时间值，例如`1s`或`2m`。一个绝对值`1`表示的是1毫秒，无疑会使你的集群陷入瘫痪)  
```
PUT /my_logs
{
  "settings": {
    "refresh_interval": "30s"
  }
}
```
4. 关闭自动刷新(在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来)  
```
PUT /my_logs/_settings
{ "refresh_interval": -1 }
```

#### 5. 持久化变更
+ 如果没有用fsync把数据从文件系统缓存刷(flush)到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证Elasticsearch的可靠性，需要确保数据变化被持久化到磁盘
+ 即使通过每秒刷新(refresh)实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。我们也不希望丢失掉两次提交之间发生变化的文档数据
+ Elasticsearch增加了一个translog，或者叫事务日志，在每一次对Elasticsearch进行操作时均进行了日志记录。通过translog，整个流程看起来是下面这样：
1. 一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了translog
2. 刷新(refresh)使分片处于刷新(refresh)完成后，缓存被清空，但是事务日志不会
3. 这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志
4. 分片每30分钟被自动刷新(flush)，或者在translog太大的时候也会刷新。一个新的translog被创建，并且一个全量提交被执行
+ translog提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放translog中所有在最后一次提交后发生的变更操作
+ translog也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本
1. 手动刷新`blogs`索引 `POST /blogs/_flush`
2. 手动刷新所有索引，并在其完成后返回结果 `POST /_flush?wait_for_ongoing`
3. 设置translog的fsync间隔(提升一些性能，但是有丢失几秒数据的风险)(默认每次写请求完成后都fsync，默认参数`"index.translog.durability": "request"`)
```
PUT /my_index/_settings
{
  "index.translog.durability": "async",
  "index.translog.sync_interval": "5s"
}
```

#### 6. 段合并
+ 由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦(每一个段都会消耗文件句柄、内存和cpu运行周期)，每个搜索请求都必须轮流检查每个段，段越多，搜索也就越慢
+ Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档(或被更新文档的旧版本)不会被拷贝到新的大段中
+ 启动段合并不需要你做任何事，进行索引和搜索时会自动进行。合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行
+ 手动合并索引为一个段(可能会消耗很多资源使节点不能正常使用) `POST /logstash-2014-10/_optimize?max_num_segments=1`